{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-Class Activity - Cyber Security Data Analysis \n",
    "This notebook will guide you through the process of analyzing a cyber security dataset. Follow the TODO tasks to complete the assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Importing the required libraries\n",
    "\n",
    "TODO: Import the necessary libraries for data analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "pd.options.display.max_rows = 999\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Loading the dataset\n",
    "\n",
    "TODO: Load the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"./Data/CySecData.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Display the first few rows of the dataset\n",
    "TODO: Import the necessary libraries for data analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
      "0         0           tcp  ftp_data   SF        491          0     0   \n",
      "1         0           udp     other   SF        146          0     0   \n",
      "2         0           tcp   private   S0          0          0     0   \n",
      "3         0           tcp      http   SF        232       8153     0   \n",
      "4         0           tcp      http   SF        199        420     0   \n",
      "\n",
      "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
      "0               0       0    0  ...                  25   \n",
      "1               0       0    0  ...                   1   \n",
      "2               0       0    0  ...                  26   \n",
      "3               0       0    0  ...                 255   \n",
      "4               0       0    0  ...                 255   \n",
      "\n",
      "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
      "0                    0.17                    0.03   \n",
      "1                    0.00                    0.60   \n",
      "2                    0.10                    0.05   \n",
      "3                    1.00                    0.00   \n",
      "4                    1.00                    0.00   \n",
      "\n",
      "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
      "0                         0.17                         0.00   \n",
      "1                         0.88                         0.00   \n",
      "2                         0.00                         0.00   \n",
      "3                         0.03                         0.04   \n",
      "4                         0.00                         0.00   \n",
      "\n",
      "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
      "0                  0.00                      0.00                  0.05   \n",
      "1                  0.00                      0.00                  0.00   \n",
      "2                  1.00                      1.00                  0.00   \n",
      "3                  0.03                      0.01                  0.00   \n",
      "4                  0.00                      0.00                  0.00   \n",
      "\n",
      "   dst_host_srv_rerror_rate    class  \n",
      "0                      0.00   normal  \n",
      "1                      0.00   normal  \n",
      "2                      0.00  anomaly  \n",
      "3                      0.01   normal  \n",
      "4                      0.00   normal  \n",
      "\n",
      "[5 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "# display the first 5 rows of the dataset\n",
    "def display_data():\n",
    "    df = pd.read_csv(link)\n",
    "    print(df.head(5))\n",
    "    return df\n",
    "df = display_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Initial info on the dataset.\n",
    "\n",
    "TODO: Provide a summary of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Creating dummy variables\n",
    "TODO: Create dummy variables for the categorical columns except for the label column \"class\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDummies = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Dropping the target column\n",
    "TODO: Drop the target column 'class' from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfDummies = dfDummies.drop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Importing the Standard Scaler\n",
    "TODO: Import the `StandardScaler` from `sklearn.preprocessing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Scaling the dataset\n",
    "TODO: Scale the dataset using the `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfNormalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Splitting the dataset\n",
    "TODO: Split the dataset into features (X) and target (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = \n",
    "y = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Importing the required libraries for the models\n",
    "TODO: Import the necessary libraries for model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 11: Defining the models (Logistic Regression, Support Vector Machine, Random Forest)\n",
    "TODO: Define the models to be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('SVM', SVC()))\n",
    "models.append(('RandomForestClassifier', RandomForestClassifier()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 12: Evaluating the models\n",
    "TODO: Evaluate the models using 10 fold cross-validation and display the mean and standard deviation of the accuracy.\n",
    "Hint: Use Kfold cross validation and a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 13: Converting the notebook to a script\n",
    "TODO: Convert the notebook to a script using the `nbconvert` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cysecenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
