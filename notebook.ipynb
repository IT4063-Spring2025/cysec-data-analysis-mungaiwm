{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-Class Activity - Cyber Security Data Analysis \n",
    "This notebook will guide you through the process of analyzing a cyber security dataset. Follow the TODO tasks to complete the assignment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Importing the required libraries\n",
    "\n",
    "TODO: Import the necessary libraries for data analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "pd.options.display.max_rows = 999\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Loading the dataset\n",
    "\n",
    "TODO: Load the given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = \"./Data/CySecData.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Display the first few rows of the dataset\n",
    "TODO: Import the necessary libraries for data analysis and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
      "0         0           tcp  ftp_data   SF        491          0     0   \n",
      "1         0           udp     other   SF        146          0     0   \n",
      "2         0           tcp   private   S0          0          0     0   \n",
      "3         0           tcp      http   SF        232       8153     0   \n",
      "4         0           tcp      http   SF        199        420     0   \n",
      "\n",
      "   wrong_fragment  urgent  hot  ...  dst_host_srv_count  \\\n",
      "0               0       0    0  ...                  25   \n",
      "1               0       0    0  ...                   1   \n",
      "2               0       0    0  ...                  26   \n",
      "3               0       0    0  ...                 255   \n",
      "4               0       0    0  ...                 255   \n",
      "\n",
      "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
      "0                    0.17                    0.03   \n",
      "1                    0.00                    0.60   \n",
      "2                    0.10                    0.05   \n",
      "3                    1.00                    0.00   \n",
      "4                    1.00                    0.00   \n",
      "\n",
      "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
      "0                         0.17                         0.00   \n",
      "1                         0.88                         0.00   \n",
      "2                         0.00                         0.00   \n",
      "3                         0.03                         0.04   \n",
      "4                         0.00                         0.00   \n",
      "\n",
      "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
      "0                  0.00                      0.00                  0.05   \n",
      "1                  0.00                      0.00                  0.00   \n",
      "2                  1.00                      1.00                  0.00   \n",
      "3                  0.03                      0.01                  0.00   \n",
      "4                  0.00                      0.00                  0.00   \n",
      "\n",
      "   dst_host_srv_rerror_rate    class  \n",
      "0                      0.00   normal  \n",
      "1                      0.00   normal  \n",
      "2                      0.00  anomaly  \n",
      "3                      0.01   normal  \n",
      "4                      0.00   normal  \n",
      "\n",
      "[5 rows x 42 columns]\n"
     ]
    }
   ],
   "source": [
    "# display the first 5 rows of the dataset\n",
    "def display_data():\n",
    "    df = pd.read_csv(link)\n",
    "    print(df.head(5))\n",
    "    return df\n",
    "df = display_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Initial info on the dataset.\n",
    "\n",
    "TODO: Provide a summary of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25192 entries, 0 to 25191\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   duration                     25192 non-null  int64  \n",
      " 1   protocol_type                25192 non-null  object \n",
      " 2   service                      25192 non-null  object \n",
      " 3   flag                         25192 non-null  object \n",
      " 4   src_bytes                    25192 non-null  int64  \n",
      " 5   dst_bytes                    25192 non-null  int64  \n",
      " 6   land                         25192 non-null  int64  \n",
      " 7   wrong_fragment               25192 non-null  int64  \n",
      " 8   urgent                       25192 non-null  int64  \n",
      " 9   hot                          25192 non-null  int64  \n",
      " 10  num_failed_logins            25192 non-null  int64  \n",
      " 11  logged_in                    25192 non-null  int64  \n",
      " 12  num_compromised              25192 non-null  int64  \n",
      " 13  root_shell                   25192 non-null  int64  \n",
      " 14  su_attempted                 25192 non-null  int64  \n",
      " 15  num_root                     25192 non-null  int64  \n",
      " 16  num_file_creations           25192 non-null  int64  \n",
      " 17  num_shells                   25192 non-null  int64  \n",
      " 18  num_access_files             25192 non-null  int64  \n",
      " 19  num_outbound_cmds            25192 non-null  int64  \n",
      " 20  is_host_login                25192 non-null  int64  \n",
      " 21  is_guest_login               25192 non-null  int64  \n",
      " 22  count                        25192 non-null  int64  \n",
      " 23  srv_count                    25192 non-null  int64  \n",
      " 24  serror_rate                  25192 non-null  float64\n",
      " 25  srv_serror_rate              25192 non-null  float64\n",
      " 26  rerror_rate                  25192 non-null  float64\n",
      " 27  srv_rerror_rate              25192 non-null  float64\n",
      " 28  same_srv_rate                25192 non-null  float64\n",
      " 29  diff_srv_rate                25192 non-null  float64\n",
      " 30  srv_diff_host_rate           25192 non-null  float64\n",
      " 31  dst_host_count               25192 non-null  int64  \n",
      " 32  dst_host_srv_count           25192 non-null  int64  \n",
      " 33  dst_host_same_srv_rate       25192 non-null  float64\n",
      " 34  dst_host_diff_srv_rate       25192 non-null  float64\n",
      " 35  dst_host_same_src_port_rate  25192 non-null  float64\n",
      " 36  dst_host_srv_diff_host_rate  25192 non-null  float64\n",
      " 37  dst_host_serror_rate         25192 non-null  float64\n",
      " 38  dst_host_srv_serror_rate     25192 non-null  float64\n",
      " 39  dst_host_rerror_rate         25192 non-null  float64\n",
      " 40  dst_host_srv_rerror_rate     25192 non-null  float64\n",
      " 41  class                        25192 non-null  object \n",
      "dtypes: float64(15), int64(23), object(4)\n",
      "memory usage: 8.1+ MB\n",
      "None\n",
      "           duration     src_bytes     dst_bytes          land  wrong_fragment  \\\n",
      "count  25192.000000  2.519200e+04  2.519200e+04  25192.000000    25192.000000   \n",
      "mean     305.054104  2.433063e+04  3.491847e+03      0.000079        0.023738   \n",
      "std     2686.555640  2.410805e+06  8.883072e+04      0.008910        0.260221   \n",
      "min        0.000000  0.000000e+00  0.000000e+00      0.000000        0.000000   \n",
      "25%        0.000000  0.000000e+00  0.000000e+00      0.000000        0.000000   \n",
      "50%        0.000000  4.400000e+01  0.000000e+00      0.000000        0.000000   \n",
      "75%        0.000000  2.790000e+02  5.302500e+02      0.000000        0.000000   \n",
      "max    42862.000000  3.817091e+08  5.151385e+06      1.000000        3.000000   \n",
      "\n",
      "            urgent           hot  num_failed_logins     logged_in  \\\n",
      "count  25192.00000  25192.000000       25192.000000  25192.000000   \n",
      "mean       0.00004      0.198039           0.001191      0.394768   \n",
      "std        0.00630      2.154202           0.045418      0.488811   \n",
      "min        0.00000      0.000000           0.000000      0.000000   \n",
      "25%        0.00000      0.000000           0.000000      0.000000   \n",
      "50%        0.00000      0.000000           0.000000      0.000000   \n",
      "75%        0.00000      0.000000           0.000000      1.000000   \n",
      "max        1.00000     77.000000           4.000000      1.000000   \n",
      "\n",
      "       num_compromised  ...  dst_host_count  dst_host_srv_count  \\\n",
      "count     25192.000000  ...    25192.000000        25192.000000   \n",
      "mean          0.227850  ...      182.532074          115.063036   \n",
      "std          10.417352  ...       98.993895          110.646850   \n",
      "min           0.000000  ...        0.000000            0.000000   \n",
      "25%           0.000000  ...       84.000000           10.000000   \n",
      "50%           0.000000  ...      255.000000           61.000000   \n",
      "75%           0.000000  ...      255.000000          255.000000   \n",
      "max         884.000000  ...      255.000000          255.000000   \n",
      "\n",
      "       dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
      "count            25192.000000            25192.000000   \n",
      "mean                 0.519791                0.082539   \n",
      "std                  0.448944                0.187191   \n",
      "min                  0.000000                0.000000   \n",
      "25%                  0.050000                0.000000   \n",
      "50%                  0.510000                0.030000   \n",
      "75%                  1.000000                0.070000   \n",
      "max                  1.000000                1.000000   \n",
      "\n",
      "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
      "count                 25192.000000                 25192.000000   \n",
      "mean                      0.147453                     0.031844   \n",
      "std                       0.308367                     0.110575   \n",
      "min                       0.000000                     0.000000   \n",
      "25%                       0.000000                     0.000000   \n",
      "50%                       0.000000                     0.000000   \n",
      "75%                       0.060000                     0.020000   \n",
      "max                       1.000000                     1.000000   \n",
      "\n",
      "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
      "count          25192.000000              25192.000000          25192.000000   \n",
      "mean               0.285800                  0.279846              0.117800   \n",
      "std                0.445316                  0.446075              0.305869   \n",
      "min                0.000000                  0.000000              0.000000   \n",
      "25%                0.000000                  0.000000              0.000000   \n",
      "50%                0.000000                  0.000000              0.000000   \n",
      "75%                1.000000                  1.000000              0.000000   \n",
      "max                1.000000                  1.000000              1.000000   \n",
      "\n",
      "       dst_host_srv_rerror_rate  \n",
      "count              25192.000000  \n",
      "mean                   0.118769  \n",
      "std                    0.317333  \n",
      "min                    0.000000  \n",
      "25%                    0.000000  \n",
      "50%                    0.000000  \n",
      "75%                    0.000000  \n",
      "max                    1.000000  \n",
      "\n",
      "[8 rows x 38 columns]\n"
     ]
    }
   ],
   "source": [
    "# provide a summary of the dataset\n",
    "def summary_data():\n",
    "    print(df.info())\n",
    "    print(df.describe())\n",
    "    return df\n",
    "df = summary_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Creating dummy variables\n",
    "TODO: Create dummy variables for the categorical columns except for the label column \"class\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration  src_bytes  dst_bytes  land  wrong_fragment  urgent  hot  \\\n",
      "0         0        491          0     0               0       0    0   \n",
      "1         0        146          0     0               0       0    0   \n",
      "2         0          0          0     0               0       0    0   \n",
      "3         0        232       8153     0               0       0    0   \n",
      "4         0        199        420     0               0       0    0   \n",
      "\n",
      "   num_failed_logins  logged_in  num_compromised  ...  flag_REJ  flag_RSTO  \\\n",
      "0                  0          0                0  ...     False      False   \n",
      "1                  0          0                0  ...     False      False   \n",
      "2                  0          0                0  ...     False      False   \n",
      "3                  0          1                0  ...     False      False   \n",
      "4                  0          1                0  ...     False      False   \n",
      "\n",
      "   flag_RSTOS0  flag_RSTR  flag_S0  flag_S1  flag_S2  flag_S3  flag_SF  \\\n",
      "0        False      False    False    False    False    False     True   \n",
      "1        False      False    False    False    False    False     True   \n",
      "2        False      False     True    False    False    False    False   \n",
      "3        False      False    False    False    False    False     True   \n",
      "4        False      False    False    False    False    False     True   \n",
      "\n",
      "   flag_SH  \n",
      "0    False  \n",
      "1    False  \n",
      "2    False  \n",
      "3    False  \n",
      "4    False  \n",
      "\n",
      "[5 rows x 115 columns]\n"
     ]
    }
   ],
   "source": [
    "# Create dummy variables for categorical columns except for the label column \"class\"\n",
    "def create_dummies(df):\n",
    "    # Select categorical columns excluding 'class'\n",
    "    categorical_columns = [col for col in df.select_dtypes(include=['object']).columns if col != 'class']\n",
    "    \n",
    "    # Create dummy variables\n",
    "    dfDummies = pd.get_dummies(df, columns=categorical_columns, drop_first=True)\n",
    "    \n",
    "    return dfDummies\n",
    "\n",
    "# Assuming 'df' is the original DataFrame\n",
    "dfDummies = create_dummies(df)\n",
    "\n",
    "# Display the first few rows of the transformed DataFrame\n",
    "print(dfDummies.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: Dropping the target column\n",
    "TODO: Drop the target column 'class' from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the target column 'class' from the dataset\n",
    "def drop_target(df):\n",
    "    if 'class' in df.columns:\n",
    "        df = df.drop(columns=['class'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop the target column 'class' from the dataset.\n",
    "def drop_target():\n",
    "    df.drop(columns=[\"class\"], inplace=True)\n",
    "    return df\n",
    "df = drop_target()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column 'class' to the dataset\n",
    "def add_class_column(df):\n",
    "    df['class'] = df['class'].map({'no': 0, 'yes': 1})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7: Importing the Standard Scaler\n",
    "TODO: Import the `StandardScaler` from `sklearn.preprocessing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the StandardScaler from sklearn.preprocessing.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Create an instance of the StandardScaler.\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8: Scaling the dataset\n",
    "TODO: Scale the dataset using the `StandardScaler`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration  src_bytes  dst_bytes     land  wrong_fragment    urgent  \\\n",
      "0 -0.113551  -0.009889  -0.039310 -0.00891       -0.091223 -0.006301   \n",
      "1 -0.113551  -0.010032  -0.039310 -0.00891       -0.091223 -0.006301   \n",
      "2 -0.113551  -0.010093  -0.039310 -0.00891       -0.091223 -0.006301   \n",
      "3 -0.113551  -0.009996   0.052473 -0.00891       -0.091223 -0.006301   \n",
      "4 -0.113551  -0.010010  -0.034582 -0.00891       -0.091223 -0.006301   \n",
      "\n",
      "        hot  num_failed_logins  logged_in  num_compromised  ...  flag_REJ  \\\n",
      "0 -0.091933           -0.02622  -0.807626        -0.021873  ... -0.310562   \n",
      "1 -0.091933           -0.02622  -0.807626        -0.021873  ... -0.310562   \n",
      "2 -0.091933           -0.02622  -0.807626        -0.021873  ... -0.310562   \n",
      "3 -0.091933           -0.02622   1.238197        -0.021873  ... -0.310562   \n",
      "4 -0.091933           -0.02622   1.238197        -0.021873  ... -0.310562   \n",
      "\n",
      "   flag_RSTO  flag_RSTOS0  flag_RSTR   flag_S0   flag_S1   flag_S2   flag_S3  \\\n",
      "0   -0.11052    -0.028884  -0.141864 -0.620862 -0.059207 -0.028884 -0.024409   \n",
      "1   -0.11052    -0.028884  -0.141864 -0.620862 -0.059207 -0.028884 -0.024409   \n",
      "2   -0.11052    -0.028884  -0.141864  1.610663 -0.059207 -0.028884 -0.024409   \n",
      "3   -0.11052    -0.028884  -0.141864 -0.620862 -0.059207 -0.028884 -0.024409   \n",
      "4   -0.11052    -0.028884  -0.141864 -0.620862 -0.059207 -0.028884 -0.024409   \n",
      "\n",
      "    flag_SF  flag_SH  \n",
      "0  0.826133 -0.04135  \n",
      "1  0.826133 -0.04135  \n",
      "2 -1.210459 -0.04135  \n",
      "3  0.826133 -0.04135  \n",
      "4  0.826133 -0.04135  \n",
      "\n",
      "[5 rows x 115 columns]\n"
     ]
    }
   ],
   "source": [
    "# Scale the dataset using the StandardScaler\n",
    "def scale_data(df):\n",
    "    # Fit the scaler to the data and transform it\n",
    "    scaled_data = scaler.fit_transform(df)\n",
    "    \n",
    "    # Convert the scaled data back to a DataFrame\n",
    "    df_scaled = pd.DataFrame(scaled_data, columns=df.columns)\n",
    "    \n",
    "    return df_scaled\n",
    "\n",
    "# Assuming 'dfDummies' is the DataFrame to be scaled\n",
    "dfNormalized = scale_data(dfDummies)\n",
    "\n",
    "# Display the first few rows of the scaled DataFrame\n",
    "print(dfNormalized.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 9: Splitting the dataset\n",
    "TODO: Split the dataset into features (X) and target (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df, target_column='class'):\n",
    "    # Features (X): All columns except the target column\n",
    "    X = df.loc[:, df.columns != target_column]\n",
    "    # Target (y): The target column values\n",
    "    y = df[target_column]\n",
    "    return X, y\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 10: Importing the required libraries for the models\n",
    "TODO: Import the necessary libraries for model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries for model training and evaluation\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 11: Defining the models (Logistic Regression, Support Vector Machine, Random Forest)\n",
    "TODO: Define the models to be evaluated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the models to be evaluated\n",
    "models = []\n",
    "models.append(('LR', LogisticRegression()))\n",
    "models.append(('SVM', SVC()))\n",
    "models.append(('RandomForestClassifier', RandomForestClassifier()))\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 12: Evaluating the models\n",
    "TODO: Evaluate the models using 10 fold cross-validation and display the mean and standard deviation of the accuracy.\n",
    "Hint: Use Kfold cross validation and a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models using 10 fold cross-validation and display the mean and standard deviation of the accuracy.\n",
    "\n",
    "def evaluate_models(X, y, models):\n",
    "    results = []\n",
    "    names = []\n",
    "    for name, model in models:\n",
    "        cv_results = cross_val_score(model, X, y, cv=10, scoring='accuracy')\n",
    "        results.append(cv_results)\n",
    "        names.append(name)\n",
    "        msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "        print(msg)\n",
    "    return results, names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 13: Converting the notebook to a script\n",
    "TODO: Convert the notebook to a script using the `nbconvert` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook notebook.ipynb to script\n",
      "[NbConvertApp] Writing 5376 bytes to notebook.py\n"
     ]
    }
   ],
   "source": [
    "# Convert the notebook to a script using the `nbconvert` command.\n",
    "\n",
    "!jupyter nbconvert --to script notebook.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mData\u001b[m\u001b[m             \u001b[34m__pycache__\u001b[m\u001b[m      notebook.ipynb   notebook_test.py\n",
      "README.md        \u001b[34mcysecenv\u001b[m\u001b[m         notebook.py      requirements.txt\n"
     ]
    }
   ],
   "source": [
    "# Verify the script conversion\n",
    "!ls"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cysecenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
